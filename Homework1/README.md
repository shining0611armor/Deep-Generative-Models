# 📊 Probability and Statistical Foundations  
### Deep Generative Models – Homework 1  
**K. N. Toosi University of Technology**  
**Spring 1404 (2025)**  
**Instructor:** Dr. B. Nasihatkon  

📘 **Course Level:** Master’s & PhD  
📦 **Homework Designed By:** Mehran Tamjidi (Head Teaching Assistant)  

This repository contains **Homework 1** for the graduate-level course **Deep Generative Models**, taught by Dr. B. Nasihatkon at **K. N. Toosi University of Technology** during **Spring 1404 (2025)**.

The homework focuses on fundamental probability and statistical concepts relevant to deep generative modeling, including:

- 💧 **Probabilistic Modeling of Stone Drops in a Cylindrical Well**  
  Analyze the probability density function of stones falling within a circular well, calculate normalization constants, and explore independence and transformations to polar coordinates.

- 🔢 **Joint and Marginal Distributions of Discrete Random Variables**  
  Work through the normalization, marginal, and conditional distributions of joint PMFs involving integer-valued variables, including use of the Riemann zeta function.

- 📊 **Joint Distributions and Independence Tests**  
  Given tabulated joint PMFs, derive marginals, conditionals, and analyze independence of discrete random variables.

- 🔗 **Conditional Independence Proofs**  
  Demonstrate conditional independence properties for factorized joint distributions.

- 📐 **Parameter Counting in Discrete Distributions**  
  Compute the minimum number of free parameters required to fully specify joint and conditional distributions over discrete variables with known domains and independence assumptions.

> 🛠️ This homework aims to build a solid probabilistic foundation essential for understanding and developing deep generative models.

---

